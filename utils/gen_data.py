import csv
import random
import argparse
import numpy as np
import json

'''
Take in verb-object and object-embedding pairs,
and generate command-embedding pairs for training and testing of the model
'''

'''
verb-object와 object-embedding pair를 입력으로 받고, command-embedding pair를 만듦
'''




parser = argparse.ArgumentParser()
#annotated verb-object pairs data
parser.add_argument('--inputVO', type=str, default='../data/annotated-vo.csv', help='input verb-object file') #verb-object가 무작위로 들어있는 파일 1이있는 label이 적절한 label
#below file is generated by resnet.py
parser.add_argument('--inputOA', type=str, default='../data/object-embedding.csv', help='input object-embedding file') #object embedding이 들어있는 파일
parser.add_argument('--train', type=str, default='../data/corpus-train.csv', help='output file')
parser.add_argument('--test', type=str, default='../data/corpus-test.csv', help='output file')
opt = parser.parse_args()

#only use the verb in generating natural language commands,
#if set to False then use both the verb and object/noun
verb_only = True #False라 하면 verb와 object/noun을 모두 사용
#threshold value to filter out verbs that can only be paired with very few objects
THRESHOLD = 5 #극소수의 객체와 쌍을 이룰 수 있는 동사를 걸러내는 임계값
data_aug = 10 # rate of data augmentation ??

# Generates a string/command from templates
# template을 이용하여 command를 생성
def gen_from_template(verb, obj):
    pre_obj = ['Give me the ', 'Hand me the ', 'Pass me the ', 'Fetch the ',
           'Get the ', 'Bring the ', 'Bring me the ',
           'I need the ', 'I want the ',
           'I need a ', 'I want a ']

    pre_verb = ['An item that can ', 'An object that can ',
           'Give me something that can ', 'Give me an item that can ',
           'Hand me something with which I can ',
           'Give me something with which I can ',
           'Hand me something to ', 'Give me something to ',
           'I want something to ', 'I need something to ']

    if verb_only:
        template = random.choice(pre_verb)
        sentence = template + verb
    else:
        template = random.choice(pre_obj)
        sentence = template + obj + ' to ' + verb
    return sentence


with open(opt.inputVO, 'r') as inputVOFile: #verb-object가 무작위로 들어있는 파일에 대해서
    with open(opt.inputOA, 'r') as inputOAFile: #object embedding이 들어있는 파일에 대해서
        with open(opt.train, 'w', newline='') as outputTrain: #corpus-train에 대해서
            with open(opt.test, 'w', newline='') as outputTest: #corpus-test에 대해서
                # csv.writer를 이용하여 저장
                writer_train = csv.writer(outputTrain, delimiter=',') #,로 데이터 구분
                writer_test = csv.writer(outputTest, delimiter=',')
                voData = list(csv.reader(inputVOFile))
                oaData = list(csv.reader(inputOAFile))

                aff_dict = {}
                for row in oaData:
                    obj = str(row[0]).lower()
                    aff = str(row[1])
                    img = str(row[2])
                    if obj not in aff_dict: #aff_dict에 obj가 없는 경우에 대해서만
                        aff_dict[obj] = []
                    aff_dict[obj].append([aff, img]) #aff와 img를 dictionary값에 넣어줌

                vo_dict = {}
                objects = []
                for row in voData:
                    verb = str(row[0])
                    obj = str(row[1])
                    label = str(row[2]) #없으면 어떻게>?
                    #if the verb-object pair is annotated to be valid
                    if (len(label) > 0): #있는 경유에
                        if verb not in vo_dict: #verb가 없으면
                            vo_dict[verb] = [] #verb를 key로 가지는 list 생성
                        if obj not in vo_dict[verb]: #해당 list에 obj가 없으면
                            vo_dict[verb].append(obj) #obj 축가
                        if obj not in objects: #obj가 objects list에 없는 경우
                            objects.append(obj) #list에 obj 추가

                #vo_dict.json파일에 적절한 vo데이터만 저장
                with open('../data/vo_dict.json', 'w+') as f: 
                    f.write(json.dumps(vo_dict))

                verbs = []
                for v, obj in vo_dict.items():
                    if (len(obj) >= THRESHOLD): #verb에 해당하는 object가 5개 이상인 경우에
                        verbs.append(v)

                #holdout 20% of the object classes for testing
                # object에 대해서
                test = random.sample(objects, k=int(len(objects)/5)) #왜 len(objects)/5 이렇게?
                train = []
                for o in objects:
                    if o not in test:
                        train.append(o) #test에 없으면 train에 추가

                for v, obj in vo_dict.items():
                    for o in obj:
                        if v in verbs:
                            if o in train:
                                #each verb-object pair datapoint is augmented
                                #by generating a different natural language command
                                #and pairing it with a randomly selected image/embedding of the object
                                #10번 반복해서 sentence 생성
                                for i in range(data_aug):
                                    sentence = gen_from_template(v, o)
                                    aff, img = random.choice(aff_dict[o])
                                    row = (v, o, sentence, aff, img)
                                    writer_train.writerow(row)
                            else:
                                sentence = gen_from_template(v, o)
                                aff, img = random.choice(aff_dict[o])
                                row = (v, o, sentence, aff, img)
                                writer_test.writerow(row)
